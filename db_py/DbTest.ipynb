{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/test/risksoft/TS/db_py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir(\"../test123\")\n",
    "except FileNotFoundError:\n",
    "    os.makedirs(\"../test123\")\n",
    "    os.chdir(\"../test123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store pdata of values cl to tw/pdata/cl.parquet successful\n",
      "store pdata of values cl to tw/pdata/cl_pct.parquet successful\n",
      "store pdata of values op to tw/pdata/op.parquet successful\n",
      "store pdata of values op to tw/pdata/op_pct.parquet successful\n",
      "store pdata of values vol(volume) to tw/pdata/vol(volume).parquet successful\n",
      "store pdata of values vol(volume) to tw/pdata/vol(volume)_pct.parquet successful\n",
      "store pdata of values vol(turnover) to tw/pdata/vol(turnover).parquet successful\n",
      "store pdata of values vol(turnover) to tw/pdata/vol(turnover)_pct.parquet successful\n"
     ]
    }
   ],
   "source": [
    "directory = 'tw/price'\n",
    "list_ = os.listdir(directory)\n",
    "df_list = [pd.read_parquet(os.path.join(directory, i)) for i in list_]\n",
    "df_all = pd.concat(df_list)\n",
    "df_all['da1'] = df_all['da'].apply(lambda x: f\"{int(x[:3])+1911}-{x[4:6]}-{x[7:9]}\")\n",
    "df = df_all.drop_duplicates(subset=['ticker', 'da1'])\n",
    "df['da_check'] = df['da1'].astype(str).apply(lambda x: int(x[:4]))\n",
    "df_final = df[df['da_check'].isin([i for i in range(2018, 2026)])]\n",
    "\n",
    "for values in ['cl', 'op', 'vol(volume)', 'vol(turnover)']:\n",
    "    df_pivot = df_final.pivot(values=values, columns='ticker', index='da1')\n",
    "    df_pivot.replace(\"--\", None, inplace=True)\n",
    "    df_pivot.replace(\"-\", None, inplace=True)\n",
    "    df_pivot.ffill(inplace=True)\n",
    "    df_pivot = df_pivot.loc['2018-01-01':(datetime.now()+timedelta(days=1)).strftime(\"%Y-%m-%d\")]\n",
    "    df_pivot.sort_index(ascending=True, inplace=True)\n",
    "    df_pivot = df_pivot.apply(lambda x: x.str.replace(',', '').astype(float))\n",
    "    df_pivot.dropna(how='all', axis=1, inplace=True)\n",
    "    df_pivot.to_parquet(f\"tw/pdata/{values}.parquet\")\n",
    "    print(f\"store pdata of values {values} to tw/pdata/{values}.parquet successful\")\n",
    "    df_pivot_pct = df_pivot.pct_change().dropna()\n",
    "    df_pivot.to_parquet(f\"tw/pdata/{values}_pct.parquet\")\n",
    "    print(f\"store pdata of values {values} to tw/pdata/{values}_pct.parquet successful\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store pdata of values pe to tw/pdata/pe.parquet successful\n",
      "store pdata of values pb to tw/pdata/pb.parquet successful\n"
     ]
    }
   ],
   "source": [
    "directory = 'tw/pb_ratio'\n",
    "list_ = os.listdir(directory)\n",
    "df_list = [pd.read_parquet(os.path.join(directory, i)) for i in list_]\n",
    "df_all = pd.concat(df_list)\n",
    "df_all['da'] = df_all.index\n",
    "df = df_all.drop_duplicates(subset=['ticker', 'da'])\n",
    "for values in ['pe', 'pb']:\n",
    "    df_pivot = df.pivot(values=values, columns='ticker', index='da')\n",
    "\n",
    "    df_pivot.replace(\"--\", None, inplace=True)\n",
    "    df_pivot.replace(\"-\", None, inplace=True)\n",
    "    df_pivot.ffill(inplace=True)\n",
    "    df_pivot = df_pivot.loc['2018-01-01':(datetime.now()+timedelta(days=1)).strftime(\"%Y-%m-%d\")]\n",
    "    df_pivot.sort_index(ascending=True, inplace=True)\n",
    "    df_pivot = df_pivot.apply(lambda x: x.str.replace(',', '').astype(float))\n",
    "    df_pivot.dropna(how='all', axis=1, inplace=True)\n",
    "    df_pivot.to_parquet(f\"tw/pdata/{values}.parquet\")\n",
    "    print(f\"store pdata of values {values} to tw/pdata/{values}.parquet successful\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 富櫃50 TPEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "list_list = []\n",
    "for year in range(113, 102, -1):\n",
    "    limit_month = 8 if year == 113 else 13\n",
    "    for index, month in enumerate(range(1, limit_month)):\n",
    "        month = f\"0{month}\" if month < 10 else month\n",
    "        url_gretai50 = f\"https://www.tpex.org.tw/web/stock/iNdex_info/gretai50/inxhis/rihisqry_result.php?l=zh-tw&d={year}/{month}/01&_=1720688879318\"\n",
    "        response = requests.get(url_gretai50)\n",
    "        data = response.json()['aaData']\n",
    "        list_list.append(data)\n",
    "list_ = sum(list_list, [])\n",
    "df = pd.DataFrame(list_)\n",
    "df.to_parquet('../db/tw/ind/gretai50.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 財報, selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cd /Users/test/risksoft/TS/db/chromedriver_mac/chromedriver-mac-x64/\n",
    "chmod +x chromedriver\n",
    "\n",
    "or\n",
    "\n",
    "chmod +x /Users/test/risksoft/TS/db/chromedriver_mac/chromedriver-mac-x64/chromedriver\n",
    "\n",
    "so that auto generated chromedriver can be reached and executed\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# 初始化 Selenium WebDriver\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")\n",
    "service = Service(executable_path=obj.chromedriver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/test/risksoft/TS/db'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"../db/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/test/risksoft/TS/db'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BS_hist(driver, ticker='2330', year=112, season=1):\n",
    "\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    select_element = wait.until(EC.presence_of_element_located((By.ID, 'isnew')))\n",
    "    select = Select(select_element)\n",
    "    select.select_by_visible_text('歷史資料')\n",
    "\n",
    "    company_code_input = wait.until(EC.presence_of_element_located((By.ID, 'co_id')))\n",
    "    company_code_input.send_keys(ticker)\n",
    "\n",
    "    year_input = driver.find_element(By.ID, 'year')\n",
    "    year_input.send_keys(str(year))\n",
    "\n",
    "    select_element = wait.until(EC.presence_of_element_located((By.ID, 'season')))\n",
    "    select = Select(select_element)\n",
    "    select.select_by_visible_text(str(season))\n",
    "\n",
    "    search_button = driver.find_element(By.CSS_SELECTOR, 'input[type=\"button\"][value=\" 查詢 \"]')\n",
    "    search_button.click()\n",
    "\n",
    "    wait.until(EC.presence_of_element_located((By.ID, 'table01')))\n",
    "    try_ = 2\n",
    "    sleep_ = 2\n",
    "    for i in range(try_):\n",
    "        try:\n",
    "            time.sleep(sleep_)\n",
    "            data = []\n",
    "            table = driver.find_element(By.CLASS_NAME, 'hasBorder')\n",
    "            rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "            for row in rows:\n",
    "                cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "                cols = [col.text for col in cols]\n",
    "                data.append(cols)\n",
    "                df = pd.DataFrame(data)\n",
    "            break\n",
    "        except:\n",
    "            print(f\"attemp {i}/{try_}\")\n",
    "    return df\n",
    "\n",
    "def clean_BS_hist(df, year=112, season=1):\n",
    "    season_dict = {\n",
    "    1: '03-31',\n",
    "    2: \"06-30\",\n",
    "    3: \"09-30\",\n",
    "    4: \"12-31\",\n",
    "    }\n",
    "\n",
    "    slices = {\n",
    "        'df_current': slice(5, 15),\n",
    "        'df_noncurrent': slice(18, 25),\n",
    "        'df_total_asset': 26,\n",
    "        'df_currentlia': slice(28, 36),\n",
    "        'df_noncurrentlia': slice(38, 43),\n",
    "        'df_total_lia': 44,\n",
    "        'df_equity': slice(-5, -3)\n",
    "    }\n",
    "\n",
    "    # Create the sliced DataFrames\n",
    "    df_sp = df.iloc[:, [0, 1, 2, -2, -1]]\n",
    "    dfs = {name: df_sp.iloc[s] if isinstance(s, slice) else df_sp.iloc[[s], :] for name, s in slices.items()}\n",
    "    df_concat = pd.concat(dfs.values())\n",
    "    df_concat.insert(3, \"season_da1\", f\"{1911+year}-{season_dict[season]}\")\n",
    "    df_concat.insert(4, \"name2\", df_concat.iloc[:, 0])\n",
    "    df_concat.insert(7, \"season_da2\", f\"{1911+year-1}-{season_dict[season]}\")\n",
    "    array_f = df_concat.values.reshape(int(df_concat.shape[0]*2), int(df_concat.shape[1]/2))\n",
    "    return array_f\n",
    "\n",
    "def BS(ticker='2330', year=112, season=1):\n",
    "    arrs = []\n",
    "    driver = webdriver.Chrome()\n",
    "    url = 'https://mops.twse.com.tw/mops/web/t164sb03'\n",
    "    driver.get(url)\n",
    "    \n",
    "    df = get_BS_hist(driver, ticker, year, season)\n",
    "    arr = clean_BS_hist(df, year, season)\n",
    "    arrs.append(arr)\n",
    "    \n",
    "BS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attemp 0/3\n"
     ]
    }
   ],
   "source": [
    "season = 1\n",
    "year = 112\n",
    "driver = webdriver.Chrome()\n",
    "url = 'https://mops.twse.com.tw/mops/web/t164sb03'\n",
    "driver.get(url)\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "select_element = wait.until(EC.presence_of_element_located((By.ID, 'isnew')))\n",
    "select = Select(select_element)\n",
    "select.select_by_visible_text('歷史資料')\n",
    "\n",
    "company_code_input = wait.until(EC.presence_of_element_located((By.ID, 'co_id')))\n",
    "company_code_input.send_keys('2330')\n",
    "\n",
    "year_input = driver.find_element(By.ID, 'year')\n",
    "year_input.send_keys(str(year))\n",
    "\n",
    "select_element = wait.until(EC.presence_of_element_located((By.ID, 'season')))\n",
    "select = Select(select_element)\n",
    "select.select_by_visible_text(str(season))\n",
    "\n",
    "search_button = driver.find_element(By.CSS_SELECTOR, 'input[type=\"button\"][value=\" 查詢 \"]')\n",
    "search_button.click()\n",
    "\n",
    "wait.until(EC.presence_of_element_located((By.ID, 'table01')))\n",
    "try_ = 3\n",
    "sleep_ = 3\n",
    "for i in range(try_):\n",
    "    try:\n",
    "        data = []\n",
    "        table = driver.find_element(By.CLASS_NAME, 'hasBorder')\n",
    "        rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "        for row in rows:\n",
    "            cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "            cols = [col.text for col in cols]\n",
    "            data.append(cols)\n",
    "            df = pd.DataFrame(data)\n",
    "        break\n",
    "    except:\n",
    "        print(f\"attemp {i}/{try_}\")\n",
    "        time.sleep(sleep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 112\n",
    "season = 1\n",
    "ticker = 2330\n",
    "\n",
    "season_dict = {\n",
    "    1: ['03-31'],\n",
    "    2: [\"06-30\"],\n",
    "    3: [\"09-30\"],\n",
    "    4: [\"12-31\"],\n",
    "}\n",
    "\n",
    "slices = {\n",
    "    'df_current': slice(5, 15),\n",
    "    'df_noncurrent': slice(18, 25),\n",
    "    'df_total_asset': 26,\n",
    "    'df_currentlia': slice(28, 36),\n",
    "    'df_noncurrentlia': slice(38, 43),\n",
    "    'df_total_lia': 44,\n",
    "    'df_equity': slice(-5, -3)\n",
    "}\n",
    "\n",
    "# Create the sliced DataFrames\n",
    "df_sp = df.iloc[:, [0, 1, 2, -2, -1]]\n",
    "dfs = {name: df_sp.iloc[s] if isinstance(s, slice) else df_sp.iloc[[s], :] for name, s in slices.items()}\n",
    "df_concat = pd.concat(dfs.values())\n",
    "df_concat.insert(3, \"season_da1\", f\"{1911+year}-{season_dict[season]}\")\n",
    "df_concat.insert(4, \"name2\", df_concat.iloc[:, 0])\n",
    "df_concat.insert(7, \"season_da2\", f\"{1911+year-1}-{season_dict[season]}\")\n",
    "array_f = df_concat.values.reshape(int(df_concat.shape[0]*2), int(df_concat.shape[1]/2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
